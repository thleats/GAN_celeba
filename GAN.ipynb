{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYq4Xf4fBV0g",
        "colab_type": "text"
      },
      "source": [
        "Part 0 - Correctly load celeba dataset \n",
        "\n",
        "DONE\n",
        "\n",
        "Part 1 - Correctly implement the original GAN loss\n",
        "\n",
        "DONE\n",
        "\n",
        "Part 2 - implement training loop and train the GAN\n",
        "\n",
        "DONE\n",
        "\n",
        "![alt text](https://thleats-bucket.s3.us-east-2.amazonaws.com/CS/image_5_9060.png)\n",
        "\n",
        "![alt text](https://thleats-bucket.s3.us-east-2.amazonaws.com/ezgif.com-gif-maker(2)(1).gif)\n",
        "\n",
        "Part 3 - train on another dataset - I picked fruits (fruit-360)\n",
        "\n",
        "![alt text](https://thleats-bucket.s3.us-east-2.amazonaws.com/image_7_3460.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZblP0MQOmhb",
        "colab_type": "code",
        "outputId": "a7fcdbe9-54ae-4a31-deee-adb1839358e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "\n",
        "\n",
        "!pip install torch==1.1.0\n",
        "!pip install torchvision==0.2.1\n",
        "import sys\n",
        "print(sys.version) # python 3.6\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "print(torch.__version__) \n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time\n",
        "\n",
        "import itertools\n",
        "import pickle\n",
        "import imageio\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "\n",
        "# You can use whatever display function you want. This is a really simple one that makes decent visualizations\n",
        "def show_imgs(x,epochs,iterations, new_fig=True):\n",
        "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n",
        "    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n",
        "    if new_fig:\n",
        "        plt.figure()\n",
        "    plt.imshow(grid.numpy())\n",
        "    plt.text(0, -20, 'Epoch: ' + str(epochs) + ', ' + 'Iteration: ' + str(iterations), fontsize=20)\n",
        "    with open('/content/drive/My Drive/Lab_8_part2/image_' + str(epochs) + '_' + str(iterations) + '.png',mode='w'):\n",
        "      plt.savefig('/content/drive/My Drive/Lab_8_part2/image_' + str(epochs) + '_' + str(iterations) + '.png')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.1.0) (1.17.3)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.17.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.1) (0.46)\n",
            "3.6.8 (default, Oct  7 2019, 12:59:55) \n",
            "[GCC 8.3.0]\n",
            "1.1.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk2waXdSOvg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# helper function to initialize the weights using a normal distribution. \n",
        "# this was done in the original work (instead of xavier) and has been shown\n",
        "# to help GAN performance\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, d*8, 4, 1, 0)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d, 3, 4, 2, 1)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "        print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "        print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "        print(\"G \" + str(x.size()))\n",
        "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "        print(\"G \" + str(x.size()))\n",
        "        x = torch.tanh(self.deconv5(x))\n",
        "        print(\"G \" + str(x.size()))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=128):\n",
        "        super().__init__()\n",
        "        #self.conv0 = nn.Conv2d(3, d , 2, 4 ,2 )\n",
        "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "        self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "        self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        print(\"D \" + str(x.size()))\n",
        "        #x = F.leaky_relu(self.conv0(x), 0.2)\n",
        "        #print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        print(\"D \" + str(x.size()))\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        print(\"D \" + str(x.size()))\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "        print(\"D \" + str(x.size()))\n",
        "\n",
        "        return x\n",
        "\n",
        "#####\n",
        "# instantiate a Generator and Discriminator according to their class definition.\n",
        "#####\n",
        "D=Discriminator()\n",
        "G=Generator()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5KPW7iiPzOT",
        "colab_type": "code",
        "outputId": "f3f5bd93-48a4-45c2-b55a-2863af6f316f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "batch_size = 128\n",
        "lr = 0.0002\n",
        "train_epoch = 3\n",
        "\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "from torch.utils import data\n",
        "from os import path\n",
        "import imageio\n",
        "img_size = 64\n",
        "\n",
        "#download the data, and change the filepath\n",
        "url='https://thleats-bucket.s3.us-east-2.amazonaws.com/fruits.zip'\n",
        "location = '/content/fruits.zip'\n",
        "\n",
        "\n",
        "if path.exists(location):\n",
        "  print('already downloaded!')\n",
        "else:\n",
        "  print('downloading')\n",
        "  urllib.request.urlretrieve(url,location)\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "  with ZipFile(location, 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall()\n",
        "\n",
        "\n",
        "\n",
        "dataset=datasets.ImageFolder(root='/content/fruits-360_dataset/fruits-360/Training/',\n",
        "                                      transform=transforms.Compose([transforms.Resize(img_size),\n",
        "                                      transforms.CenterCrop(img_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), \n",
        "                                      (0.5, 0.5, 0.5)),]))\n",
        "\n",
        "\n",
        "##### Create the dataloader #####\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self,dataset):\n",
        "    'Initialization'\n",
        "    self.dataset=dataset\n",
        "  def __len__(self):\n",
        "    'Denotes the total number of samples'\n",
        "    return len(self.dataset)\n",
        "    #return 1024\n",
        "  def __getitem__(self, index):\n",
        "    'Generates one sample of data'\n",
        "    # Select sample\n",
        "    x,_ = self.dataset[index] \n",
        "    Y = index\n",
        "    return x, Y\n",
        "\n",
        "thing=Dataset(dataset)\n",
        "params={'batch_size':batch_size,'shuffle':True}\n",
        "training_generator=data.DataLoader(thing,**params)\n",
        "\n",
        "xbatch, _ = iter(training_generator).next()\n",
        "xbatch.shape\n",
        "D(xbatch)\n",
        "D(xbatch).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already downloaded!\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcem31JVGCAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator(128)\n",
        "D = Discriminator(128)\n",
        "G.weight_init(mean=0.0, std=0.02)\n",
        "D.weight_init(mean=0.0, std=0.02)\n",
        "G = G.cuda()\n",
        "D = D.cuda()\n",
        "\n",
        "# Binary Cross Entropy loss\n",
        "BCE_loss = nn.BCELoss()\n",
        "\n",
        "# Adam optimizer\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aV86RrTGIVS",
        "colab_type": "code",
        "outputId": "be99e75a-b817-4f19-9c46-25bb59697dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_iter = 0\n",
        "fixed_z_ = torch.randn(128,100,1,1) \n",
        "collect_x_gen = []\n",
        "train_epoch=8\n",
        "import pdb\n",
        "for epoch in range(train_epoch):\n",
        "    D_losses = []\n",
        "    G_losses = []\n",
        "    epoch_start_time = time.time()\n",
        "    for x_, _ in tqdm(training_generator):\n",
        "        ######################### train discriminator D ###############################\n",
        "        ###############################################################################\n",
        "        if x_.size()[0]==128:\n",
        "          D.zero_grad()\n",
        "          \n",
        "          mini_batch = x_.size()[0]\n",
        "          ##Set optimizer grads to zero\n",
        "          D_optimizer.zero_grad()\n",
        "          G_optimizer.zero_grad()\n",
        "          #create a random noise\n",
        "          z = torch.randn(mini_batch,100,1,1)\n",
        "          #create the zeros and ones vector for real and fake\n",
        "          y_real=torch.ones(x_.size(0)).cuda()\n",
        "          y_fake=torch.zeros(x_.size(0)).cuda()\n",
        "          #Pass through discriminiator - train it to recognize real images\n",
        "          D_result=D(x_.cuda()).squeeze(-1).squeeze(-1)\n",
        "          #find the real loss for the discriminator\n",
        "          D_real_loss=BCE_loss(D_result.squeeze(-1),y_real)\n",
        "          #pass the noise through the generator\n",
        "          #pdb.set_trace()\n",
        "          G_result=G(z.cuda())\n",
        "          #pass the Generated data through the discriminator\n",
        "          D_result_G=D(G_result)\n",
        "          #calculate how well the discriminator does at recognizing fake images\n",
        "          D_fake_loss=BCE_loss(D_result_G.squeeze(-1).squeeze(-1).squeeze(-1),y_fake)\n",
        "          #calculate the total loss (real + fake) - basically - how good is the discriminator at seeing real from fake\n",
        "          D_train_loss=D_real_loss+D_fake_loss\n",
        "          #backpropagation on teh network\n",
        "          D_train_loss.backward()\n",
        "          #treain the network\n",
        "          D_optimizer.step()\n",
        "          #record the losses\n",
        "          D_losses.append(D_train_loss.item())\n",
        "          #rezero the optimizers\n",
        "          D_optimizer.zero_grad()\n",
        "          G_optimizer.zero_grad()\n",
        "\n",
        "          ######################### train generator G ###############################\n",
        "          ###############################################################################\n",
        "          G.zero_grad()\n",
        "          #create more noise\n",
        "          z_new = torch.randn(128,100,1,1)\n",
        "          #pass the noise through the generator\n",
        "          G_result_G=G(z_new.cuda())\n",
        "          #pass the generated data through the discriminator\n",
        "          D_result_2=D(G_result_G)\n",
        "          #find how good the generator is at generating fakes\n",
        "          G_train_loss=BCE_loss(D_result_2.squeeze(-1).squeeze(-1).squeeze(-1),y_real)\n",
        "          #calculate the gradients\n",
        "          G_train_loss.backward()\n",
        "          #train the network\n",
        "          G_optimizer.step()    \n",
        "          #record the stuff\n",
        "          G_losses.append(G_train_loss.item())\n",
        "          \n",
        "          break\n",
        "          num_iter += 1\n",
        "\n",
        "      # generate a fixed_z_ image and save\n",
        "          if num_iter%20==0:\n",
        "            x_gen = G(fixed_z_.cuda())\n",
        "            collect_x_gen.append(x_gen.detach().clone())\n",
        "            epoch_end_time = time.time()\n",
        "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
        "\n",
        "            # print out statistics\n",
        "            print('[%d/%d] - ptime: %.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, torch.mean(torch.FloatTensor(D_losses)),\n",
        "                                                                      torch.mean(torch.FloatTensor(G_losses))))\n",
        "            \n",
        "            show_imgs(G_result[:4],epoch,num_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/473 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n",
            "G torch.Size([128, 100, 1, 1])\n",
            "G torch.Size([128, 1024, 4, 4])\n",
            "G torch.Size([128, 512, 8, 8])\n",
            "G torch.Size([128, 256, 16, 16])\n",
            "G torch.Size([128, 128, 32, 32])\n",
            "G torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 3, 64, 64])\n",
            "D torch.Size([128, 128, 32, 32])\n",
            "D torch.Size([128, 256, 16, 16])\n",
            "D torch.Size([128, 512, 8, 8])\n",
            "D torch.Size([128, 1024, 4, 4])\n",
            "D torch.Size([128, 1, 1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}